run:
  input_path: data/1_宗亲家的小娘子_8000.txt
  book_id: novel
  reset: false
  debug: true
  save_jsonl: extractions_subset.jsonl
  limit_chunks: null
  parse_max_retries: 2
  retry_backoff_s: 2.0

  # Reusable defaults for DataFactory-generated QA tasks
  qa:
    language: zh
    answer_max_chars: 40
    min_question_len: 12
    max_retries: 2
    retry_backoff_s: 2.0

    # If true, the QA generator queries Neo4j for per-chunk character spans
    # (char_start/char_end) and adds them to the prompt context.
    enrich_from_neo4j: true

chunking:
  chunk_chars: 2000
  chunk_overlap: 200

llm:
  openai:
    model: gpt-5-mini
    api_key: ${OPENAI_API_KEY}
    timeout_s: 180.0
    max_retries: 3
    max_output_tokens: 1200
    additional_kwargs: null

neo4j:
  uri: ${NEO4J_URI}
  username: ${NEO4J_USERNAME}
  password: ${NEO4J_PASSWORD}
  database: neo4j

# -----------------------------------------------------------------------------
# Each DataFactory task references one of these via chains_gen_cfg_key.
# -----------------------------------------------------------------------------
chain_gens:
  khop_default:
    enabled: true
    seed: 42
    k: [3, 4, 5]
    num_chains: 3
    max_sampling_tries: 5
    exclude_rel_types: ["MENTION"]
    start_labels: ["PERSON"]
    end_labels: []

# -----------------------------------------------------------------------------
# DataFactory
# -----------------------------------------------------------------------------
data_factory:
  enabled: true
  mode: "llm_qa"  # "chain_gen" | "llm_qa" | "all"
  tasks:
    - name: khop_qa
      chains_gen: khop_chain_gen
      chains_gen_cfg_key: khop_default
      llm_qa: khop_llm_qa
      prompt_builder: khop_qa_zh
      input_jsonl: chains/khop_chain.jsonl
      output_jsonl: outputs/khop_chain_QA.jsonl
      limit_items: null
